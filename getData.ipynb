{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando e salvando os dados da API do Youtube. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Substitua 'YOUR_API_KEY' pela sua chave de API do Google Developers Console\n",
    "api_key = 'AIzaSyChueApm22BmfGC-FuBSQLLJm8aFCODGmk'\n",
    "\n",
    "# Crie uma instância do serviço da API do YouTube Data\n",
    "youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# ID da playlist\n",
    "playlist_id = 'PLaE_mZALZ0V2E0lVJowee_oerd3OMvyJu'\n",
    "\n",
    "# Função para obter os vídeos da playlist\n",
    "def get_playlist_videos(playlist_id):\n",
    "    videos = []\n",
    "    nextPageToken = None\n",
    "\n",
    "    while True:\n",
    "        playlist_response = youtube.playlistItems().list(\n",
    "            playlistId=playlist_id,\n",
    "            part='contentDetails',\n",
    "            maxResults=50,  # Você pode ajustar o número de resultados por página\n",
    "            pageToken=nextPageToken\n",
    "        ).execute()\n",
    "\n",
    "        for item in playlist_response.get('items', []):\n",
    "            video_id = item['contentDetails']['videoId']\n",
    "            videos.append(video_id)\n",
    "\n",
    "        nextPageToken = playlist_response.get('nextPageToken')\n",
    "\n",
    "        if not nextPageToken:\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "# Função para obter informações detalhadas sobre um vídeo\n",
    "def get_video_info(video_id):\n",
    "    video_info = youtube.videos().list(\n",
    "        part='snippet,statistics,contentDetails,topicDetails',\n",
    "        id=video_id\n",
    "    ).execute()\n",
    "    \n",
    "    items = video_info.get('items', [])\n",
    "    if items:\n",
    "        return items[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Função para salvar os dados em um arquivo CSV\n",
    "def save_to_csv(video_data, filename):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Escreva o cabeçalho do arquivo CSV\n",
    "        writer.writerow([\n",
    "            \"Título\",\n",
    "            \"Descrição\",\n",
    "            \"Visualizações\",\n",
    "            \"Likes\",\n",
    "            \"Deslikes\",\n",
    "            \"Data de Publicação\",\n",
    "            \"Duração\",\n",
    "            \"Tópicos Relacionados\"\n",
    "        ])\n",
    "        # Escreva os dados de cada vídeo\n",
    "        for video_info in video_data:\n",
    "            writer.writerow([\n",
    "                video_info['snippet']['title'],\n",
    "                video_info['snippet']['description'],\n",
    "                video_info['statistics'].get('viewCount', 'N/A'),\n",
    "                video_info['statistics'].get('likeCount', 'N/A'),\n",
    "                video_info['statistics'].get('dislikeCount', 'N/A'),\n",
    "                video_info['snippet']['publishedAt'],\n",
    "                video_info['contentDetails']['duration'],\n",
    "                \", \".join(video_info['topicDetails']['topicCategories']) if 'topicDetails' in video_info else 'N/A'\n",
    "            ])\n",
    "\n",
    "# Coletar informações sobre cada vídeo na playlist\n",
    "video_ids = get_playlist_videos(playlist_id)\n",
    "video_data = []\n",
    "\n",
    "for video_id in video_ids:\n",
    "    video_info = get_video_info(video_id)\n",
    "    if video_info:\n",
    "        video_data.append(video_info)\n",
    "\n",
    "# Salvar os dados em um arquivo CSV\n",
    "save_to_csv(video_data, 'videos.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibindo os dados coletados em um DataFrame (Youtube)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando e salvando os comentários da API do Youtube. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID Vw0w6TqTW3c não possui informações disponíveis.\n",
      "Video ID ByB0Pj2_IJg não possui informações disponíveis.\n",
      "Video ID -euXX306ybA não possui informações disponíveis.\n",
      "Coleta e salvamento dos comentários concluídos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from unidecode import unidecode\n",
    "import json\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = unidecode(text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]', '', cleaned_text)\n",
    "    return cleaned_text.lower()\n",
    "\n",
    "def get_top_n_comments(comments, n=10):\n",
    "    sorted_comments = sorted(comments, key=lambda x: x[\"comment_likes\"], reverse=True)\n",
    "    return sorted_comments[:n]\n",
    "\n",
    "def save_video_top_comments(youtube, video_id, n=10):\n",
    "    video_info = youtube.videos().list(\n",
    "        part=\"snippet,statistics\",\n",
    "        id=video_id\n",
    "    ).execute()\n",
    "    \n",
    "    if \"items\" not in video_info or len(video_info[\"items\"]) == 0:\n",
    "        print(f\"Video ID {video_id} não possui informações disponíveis.\")\n",
    "        return []\n",
    "\n",
    "    video_title = video_info[\"items\"][0][\"snippet\"][\"title\"]\n",
    "    published_at = video_info[\"items\"][0][\"snippet\"][\"publishedAt\"]\n",
    "\n",
    "    video_published_date = datetime.datetime.strptime(published_at, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    start_date = datetime.datetime(2022, 2, 28)\n",
    "    end_date = datetime.datetime(2023, 10, 1)  \n",
    "\n",
    "    if start_date <= video_published_date <= end_date:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = request.execute()\n",
    "            comments_data = []\n",
    "\n",
    "            while \"items\" in response:\n",
    "                for item in response[\"items\"]:\n",
    "                    snippet = item[\"snippet\"]\n",
    "                    comment = snippet[\"topLevelComment\"][\"snippet\"]\n",
    "                    comment_data = {\n",
    "                        \"video_title\": video_title,\n",
    "                        \"comment_text\": comment[\"textDisplay\"],\n",
    "                        \"comment_author\": comment[\"authorDisplayName\"],\n",
    "                        \"comment_date\": comment[\"publishedAt\"],\n",
    "                        \"comment_likes\": comment[\"likeCount\"],\n",
    "                    }\n",
    "                    comments_data.append(comment_data)\n",
    "\n",
    "                if \"nextPageToken\" in response:\n",
    "                    token = response[\"nextPageToken\"]\n",
    "                    response = youtube.commentThreads().list(\n",
    "                        part=\"snippet\",\n",
    "                        videoId=video_id,\n",
    "                        maxResults=100,\n",
    "                        textFormat=\"plainText\",\n",
    "                        pageToken=token\n",
    "                    ).execute()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # Pegue apenas os 10 comentários mais relevantes\n",
    "            top_comments = get_top_n_comments(comments_data, n)\n",
    "\n",
    "            # Salve os 10 comentários mais relevantes no arquivo JSON\n",
    "            with open(os.path.join(DATA_DIR, \"top_comments_relevant.json\"), \"a\", encoding=\"utf-8\") as json_file:\n",
    "                for comment in top_comments:\n",
    "                    json.dump(comment, json_file, ensure_ascii=False)\n",
    "                    json_file.write(\"\\n\")\n",
    "\n",
    "            return top_comments\n",
    "\n",
    "        except HttpError as e:\n",
    "            print(e)\n",
    "    \n",
    "    return []  # Retorna uma lista vazia se o vídeo não atender aos critérios\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with open(\"apikey.txt\") as apifile:\n",
    "        api_key = apifile.read().strip()\n",
    "    api_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    playlist_url = \"https://www.youtube.com/playlist?list=PLaE_mZALZ0V2E0lVJowee_oerd3OMvyJu\"\n",
    "\n",
    "    youtube = build(api_name, api_version, developerKey=api_key)\n",
    "\n",
    "    playlist_id = playlist_url.split(\"list=\")[-1]\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    while \"items\" in response:\n",
    "        for item in response[\"items\"]:\n",
    "            snippet = item[\"snippet\"]\n",
    "            video_id = snippet[\"resourceId\"][\"videoId\"]\n",
    "            save_video_top_comments(youtube, video_id, n=10)\n",
    "\n",
    "        if \"nextPageToken\" in response:\n",
    "            token = response[\"nextPageToken\"]\n",
    "            request = youtube.playlistItems().list(\n",
    "                part=\"snippet\",\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=token\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"Coleta e salvamento dos comentários concluídos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converte JSON p/ csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados foram convertidos de <_io.TextIOWrapper name='data/top_comments_relevant.json' mode='r' encoding='utf-8'> para <_io.TextIOWrapper name='comments.csv' mode='w' encoding='utf-8'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Nome do arquivo JSON de entrada e CSV de saída\n",
    "json_file = 'data/top_comments_relevant.json'\n",
    "csv_file = 'comments.csv'\n",
    "\n",
    "# Abra o arquivo CSV para gravação\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    # Crie um objeto de escrita CSV\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Escreva o cabeçalho do CSV\n",
    "    csv_writer.writerow([\"video_title\", \"comment_text\", \"comment_author\", \"comment_date\", \"comment_likes\", \"comment_reply_count\"])\n",
    "\n",
    "    # Abra o arquivo JSON para leitura\n",
    "    with open(json_file, 'r', encoding='utf-8') as json_file:\n",
    "        for line in json_file:\n",
    "            # Parse the JSON object in the current line\n",
    "            data = json.loads(line)\n",
    "\n",
    "            # Check if the key exists in the JSON object\n",
    "            comment_reply_count = data.get(\"comment_reply_count\", \"N/A\")\n",
    "\n",
    "            # Write the data to the CSV file\n",
    "            csv_writer.writerow([\n",
    "                data.get(\"video_title\", \"N/A\"),\n",
    "                data.get(\"comment_text\", \"N/A\").replace('\\n', '\\\\n'),  # Replace newline characters with \"\\\\n\"\n",
    "                data.get(\"comment_author\", \"N/A\"),\n",
    "                data.get(\"comment_date\", \"N/A\"),\n",
    "                data.get(\"comment_likes\", \"N/A\"),\n",
    "                comment_reply_count\n",
    "            ])\n",
    "\n",
    "print(f'Os dados foram convertidos de {json_file} para {csv_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('commets.csv')\n",
    "\n",
    "df.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
