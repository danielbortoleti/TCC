{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49456</th>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>Como a média de votos era muito baixa, e o fat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49457</th>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>O enredo teve algumas reviravoltas infelizes e...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49458</th>\n",
       "      <td>I am amazed at how this movieand most others h...</td>\n",
       "      <td>Estou espantado com a forma como este filme e ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49459</th>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>A Christmas Together realmente veio antes do m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49460</th>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>O drama romântico da classe trabalhadora do di...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49459 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text_en  \\\n",
       "id                                                         \n",
       "1      Once again Mr. Costner has dragged out a movie...   \n",
       "2      This is an example of why the majority of acti...   \n",
       "3      First of all I hate those moronic rappers, who...   \n",
       "4      Not even the Beatles could write songs everyon...   \n",
       "5      Brass pictures movies is not a fitting word fo...   \n",
       "...                                                  ...   \n",
       "49456  Seeing as the vote average was pretty low, and...   \n",
       "49457  The plot had some wretched, unbelievable twist...   \n",
       "49458  I am amazed at how this movieand most others h...   \n",
       "49459  A Christmas Together actually came before my t...   \n",
       "49460  Working-class romantic drama from director Mar...   \n",
       "\n",
       "                                                 text_pt sentiment  \n",
       "id                                                                  \n",
       "1      Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "2      Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "3      Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "4      Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "5      Filmes de fotos de latão não é uma palavra apr...       neg  \n",
       "...                                                  ...       ...  \n",
       "49456  Como a média de votos era muito baixa, e o fat...       pos  \n",
       "49457  O enredo teve algumas reviravoltas infelizes e...       pos  \n",
       "49458  Estou espantado com a forma como este filme e ...       pos  \n",
       "49459  A Christmas Together realmente veio antes do m...       pos  \n",
       "49460  O drama romântico da classe trabalhadora do di...       pos  \n",
       "\n",
       "[49459 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('data/imdb-reviews-pt-br.csv', index_col=0)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['sentiment'].value_counts().plot.pie(autopct='%.2f', explode=[0.01, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 44515\n",
      "Dev samples:      2472\n",
      "Test samples:     2472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_dev_size = int(0.05*data.shape[0])\n",
    "train_dev, test = train_test_split(data, test_size=test_dev_size, random_state=42, stratify=data['sentiment'])\n",
    "train, dev = train_test_split(train_dev, test_size=test_dev_size, random_state=42, stratify=train_dev['sentiment'])\n",
    "print('Training samples:', train.shape[0])\n",
    "print('Dev samples:     ', dev.shape[0])\n",
    "print('Test samples:    ', test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImdbPt(Dataset):\n",
    "    ''' Loads IMDB-pt dataset. \n",
    "    \n",
    "    It will tokenize our inputs and cut-off sentences that exceed 512 tokens (the pretrained BERT limit)\n",
    "    '''\n",
    "    def __init__(self, tokenizer, X, y):\n",
    "        X = list(X)\n",
    "        y = list(y)\n",
    "        tokenized_data = tokenizer(X, truncation=True, max_length=512)\n",
    "        samples = [\n",
    "            {\n",
    "                **{key: tokenized_data[key][i] for key in tokenized_data},\n",
    "                'labels': y[i]\n",
    "            }\n",
    "             \n",
    "            for i in range(len(X))\n",
    "        ]\n",
    "        self.samples = samples\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.samples[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_inputs_to_device(inputs, device):\n",
    "    return {key:tensor.to(device) for key, tensor in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "train_dataset = ImdbPt(tokenizer, train['text_pt'], (train['sentiment'] == 'pos').astype(int))\n",
    "dev_dataset   = ImdbPt(tokenizer, dev['text_pt'], (dev['sentiment'] == 'pos').astype(int))\n",
    "test_dataset  = ImdbPt(tokenizer, test['text_pt'], (test['sentiment'] == 'pos').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=16, collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\João Vitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'neuralmind/bert-base-portuguese-cased')\n",
    "model.train()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9997)\n",
    "\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def evaluate(model, dev_loader, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        dev_losses = []\n",
    "        tp, tn, fp, fn = [], [], [], []\n",
    "        for inputs in dev_loader:\n",
    "            inputs = send_inputs_to_device(inputs, device)\n",
    "            loss, scores = model(**inputs)[:2]\n",
    "            dev_losses.append(loss.cpu().item())\n",
    "\n",
    "            _, classification = torch.max(scores, 1)\n",
    "            labels = inputs['labels']\n",
    "            tp.append(((classification==1) & (labels==1)).sum().cpu().item())\n",
    "            tn.append(((classification==0) & (labels==0)).sum().cpu().item())\n",
    "            fp.append(((classification==1) & (labels==0)).sum().cpu().item())\n",
    "            fn.append(((classification==0) & (labels==1)).sum().cpu().item())\n",
    "\n",
    "        tp_s, tn_s, fp_s, fn_s = sum(tp), sum(tn), sum(fp), sum(fn)\n",
    "        print('Dev loss: {:.2f}; Acc: {:.2f}; tp: {}; tn: {}; fp: {}; fn: {}'.format( \n",
    "              np.mean(dev_losses), (tp_s+tn_s)/(tp_s+tn_s+fp_s+fn_s), tp_s, tn_s, fp_s, fn_s))\n",
    "\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João Vitor\\AppData\\Local\\Temp\\ipykernel_13944\\1419208846.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  epoch_bar = tqdm_notebook(range(1))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01427d27f4d941b5a6362c6bc46f2a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\João Vitor\\AppData\\Local\\Temp\\ipykernel_13944\\1419208846.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  batch_bar = tqdm_notebook(enumerate(train_loader), desc=f'Epoch {epoch}', total=len(train_loader))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27708a1916b4cba9b08a9539fec6a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/5565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev loss: 0.70; Acc: 0.49; tp: 1184; tn: 37; fp: 1201; fn: 50\n",
      "Dev loss: 0.70; Acc: 0.50; tp: 1150; tn: 95; fp: 1143; fn: 84\n",
      "Dev loss: 0.69; Acc: 0.52; tp: 1102; tn: 181; fp: 1057; fn: 132\n",
      "Dev loss: 0.69; Acc: 0.54; tp: 1050; tn: 273; fp: 965; fn: 184\n",
      "Dev loss: 0.69; Acc: 0.54; tp: 1050; tn: 287; fp: 951; fn: 184\n",
      "Dev loss: 0.43; Acc: 0.85; tp: 976; tn: 1123; fp: 115; fn: 258\n",
      "Dev loss: 0.32; Acc: 0.88; tp: 984; tn: 1184; fp: 54; fn: 250\n",
      "Dev loss: 0.26; Acc: 0.90; tp: 1149; tn: 1065; fp: 173; fn: 85\n",
      "Dev loss: 0.24; Acc: 0.91; tp: 1141; tn: 1103; fp: 135; fn: 93\n",
      "Dev loss: 0.23; Acc: 0.91; tp: 1128; tn: 1127; fp: 111; fn: 106\n",
      "Dev loss: 0.25; Acc: 0.90; tp: 1167; tn: 1063; fp: 175; fn: 67\n",
      "Dev loss: 0.24; Acc: 0.91; tp: 1167; tn: 1072; fp: 166; fn: 67\n",
      "Dev loss: 0.23; Acc: 0.92; tp: 1104; tn: 1159; fp: 79; fn: 130\n",
      "Dev loss: 0.22; Acc: 0.92; tp: 1130; tn: 1135; fp: 103; fn: 104\n",
      "Dev loss: 0.23; Acc: 0.91; tp: 1163; tn: 1093; fp: 145; fn: 71\n",
      "Dev loss: 0.22; Acc: 0.92; tp: 1136; tn: 1133; fp: 105; fn: 98\n",
      "Dev loss: 0.21; Acc: 0.92; tp: 1139; tn: 1136; fp: 102; fn: 95\n",
      "Dev loss: 0.22; Acc: 0.92; tp: 1151; tn: 1117; fp: 121; fn: 83\n",
      "Dev loss: 0.21; Acc: 0.92; tp: 1137; tn: 1133; fp: 105; fn: 97\n",
      "Dev loss: 0.21; Acc: 0.92; tp: 1145; tn: 1128; fp: 110; fn: 89\n",
      "Dev loss: 0.21; Acc: 0.92; tp: 1129; tn: 1140; fp: 98; fn: 105\n",
      "Dev loss: 0.21; Acc: 0.92; tp: 1156; tn: 1107; fp: 131; fn: 78\n",
      "Dev loss: 0.20; Acc: 0.92; tp: 1139; tn: 1133; fp: 105; fn: 95\n",
      "Dev loss: 0.20; Acc: 0.92; tp: 1142; tn: 1131; fp: 107; fn: 92\n",
      "Dev loss: 0.21; Acc: 0.92; tp: 1149; tn: 1125; fp: 113; fn: 85\n",
      "Dev loss: 0.20; Acc: 0.92; tp: 1137; tn: 1142; fp: 96; fn: 97\n",
      "Dev loss: 0.20; Acc: 0.92; tp: 1147; tn: 1134; fp: 104; fn: 87\n",
      "Dev loss: 0.20; Acc: 0.92; tp: 1148; tn: 1135; fp: 103; fn: 86\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "epoch_bar = tqdm_notebook(range(1))\n",
    "loss_acc = 0\n",
    "alpha = 0.95\n",
    "for epoch in epoch_bar:\n",
    "    batch_bar = tqdm_notebook(enumerate(train_loader), desc=f'Epoch {epoch}', total=len(train_loader))\n",
    "    for idx, inputs in batch_bar:\n",
    "        if (epoch * len(train_loader) + idx) == 800:\n",
    "            for param in model.base_model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        inputs = send_inputs_to_device(inputs, device)\n",
    "        optimizer.zero_grad()\n",
    "        loss, logits = model(**inputs)[:2]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch == 0 and idx == 0:\n",
    "            loss_acc = loss.cpu().item()\n",
    "        else:\n",
    "            loss_acc = loss_acc * alpha + (1-alpha) * loss.cpu().item()\n",
    "        batch_bar.set_postfix(loss=loss_acc)\n",
    "        if idx%200 == 0:\n",
    "            del inputs\n",
    "            del loss\n",
    "            evaluate(model, dev_loader, device)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        \n",
    "    os.makedirs('/kaggle/working/checkpoints/epoch'+str(epoch))\n",
    "    model.save_pretrained('/kaggle/working/checkpoints/epoch'+str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positivo']\n",
      "tensor(0.6382, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    " \n",
    "inputs = tokenizer(\"\", return_tensors=\"pt\")\n",
    "output = model(**inputs)\n",
    "scores = output['logits']\n",
    "prob_pos = F.softmax(scores, dim=1)[:,1]\n",
    "\n",
    "limiar_positivo = 0.6\n",
    "limiar_negativo = 0.4\n",
    "\n",
    "# Categoriza com base nos limiares\n",
    "categorias = []\n",
    "for prob in prob_pos:\n",
    "    if prob_pos[0] >= limiar_positivo:\n",
    "        categorias.append(\"positivo\")\n",
    "    elif prob_pos[0] <= limiar_negativo:\n",
    "        categorias.append(\"negativo\")\n",
    "    else:\n",
    "        categorias.append(\"neutro\")\n",
    "\n",
    "# categorias agora contém as categorias atribuídas com base nos limiares\n",
    "print(categorias)\n",
    "\n",
    "print(prob_pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (729) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\João Vitor\\Desktop\\tcc\\TCC\\testeModelo.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o%20Vitor/Desktop/tcc/TCC/testeModelo.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m frase \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mreview_text_processed\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o%20Vitor/Desktop/tcc/TCC/testeModelo.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     inputs \u001b[39m=\u001b[39m tokenizer(frase, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o%20Vitor/Desktop/tcc/TCC/testeModelo.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o%20Vitor/Desktop/tcc/TCC/testeModelo.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     scores \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jo%C3%A3o%20Vitor/Desktop/tcc/TCC/testeModelo.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     prob_pos \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(scores, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\João Vitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\João Vitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1562\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1563\u001b[0m     input_ids,\n\u001b[0;32m   1564\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1565\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1566\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1568\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1569\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1570\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1571\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1572\u001b[0m )\n\u001b[0;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\João Vitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\João Vitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1015\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1018\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1019\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1023\u001b[0m     embedding_output,\n\u001b[0;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1033\u001b[0m )\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\João Vitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\João Vitor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:238\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    237\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m--> 238\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[0;32m    239\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n\u001b[0;32m    240\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (729) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Carrega um DataFrame pandas a partir de um arquivo CSV\n",
    "# Certifique-se de que seu arquivo CSV tem uma coluna chamada 'Frase' que contém as frases\n",
    "df = pd.read_csv('b2w.csv')  # Substitua 'seuarquivo.csv' pelo caminho para o seu arquivo CSV\n",
    "\n",
    "# Loop através das frases no DataFrame e classifique-as\n",
    "categorias = []\n",
    "for frase in df['review_text_processed']:\n",
    "    inputs = tokenizer(frase, return_tensors=\"pt\")\n",
    "    output = model(**inputs)\n",
    "    scores = output['logits']\n",
    "    prob_pos = F.softmax(scores, dim=1)[:, 1]\n",
    "\n",
    "    # Define a categoria com base nos limiares\n",
    "    if prob_pos[0] >= limiar_positivo:\n",
    "        categorias.append(\"positivo\")\n",
    "    elif prob_pos[0] <= limiar_negativo:\n",
    "        categorias.append(\"negativo\")\n",
    "    else:\n",
    "        categorias.append(\"neutro\")\n",
    "\n",
    "# Adicione as categorias como uma nova coluna no DataFrame\n",
    "df['Categoria'] = categorias\n",
    "\n",
    "# Salve o DataFrame modificado em um novo arquivo CSV\n",
    "df.to_csv('saida.csv', index=False)\n",
    "\n",
    "# Exibe o DataFrame com as categorias\n",
    "display(df)\n",
    "# print(df['Categoria'], ['review_text_processed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
